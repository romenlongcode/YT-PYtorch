{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/O7j6zPnO6WwaE825rHil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romenlongcode/YT-PYtorch/blob/main/mmo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Mtna4uhC9hvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAlJ3nA19Pgj"
      },
      "outputs": [],
      "source": [
        "class SubsetSC(torchaudio.datasets.SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(\"./\", download=True)\n",
        "\n",
        "        def load_list(filename):\n",
        "            filepath = os.path.join(self._path, filename)\n",
        "            with open(filepath) as fileobj:\n",
        "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
        "\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(\"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(\"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mel_spectrogram(waveform, sample_rate, n_mels=128, n_fft=1024, hop_length=512):\n",
        "    S = librosa.feature.melspectrogram(y=waveform.numpy(), sr=sample_rate, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
        "    log_S = librosa.power_to_db(S, ref=np.max)\n",
        "    return log_S\n"
      ],
      "metadata": {
        "id": "SOrkPV4t9YS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwQdLlhK9jzq"
      },
      "outputs": [],
      "source": [
        "def prepare_dataloader(subset, batch_size=32):\n",
        "    dataset = SubsetSC(subset=subset)\n",
        "    def collate_fn(batch):\n",
        "        tensors, targets = [], []\n",
        "        for waveform, sample_rate, label, _, _ in batch:\n",
        "            mel_spec = extract_mel_spectrogram(waveform, sample_rate)\n",
        "            tensors.append(torch.tensor(mel_spec))\n",
        "            targets.append(torch.tensor(int(label)))\n",
        "        tensors = torch.stack(tensors)\n",
        "        targets = torch.stack(targets)\n",
        "        return tensors, targets\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True\n",
        "\n",
        "train_loader = prepare_dataloader('training')\n",
        "val_loader = prepare_dataloader('validation')\n",
        "test_loader = prepare_dataloader('testing')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        planes = expansion * growthRate\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3, padding=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropRate = dropRate\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        if self.dropRate > 0:\n",
        "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
        "        out = torch.cat((x, out), 1)\n",
        "        return out\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        planes = expansion * growthRate\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3, padding=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropRate = dropRate\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        if self.dropRate > 0:\n",
        "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
        "        out = torch.cat((x, out), 1)\n",
        "        return out\n",
        "\n",
        "class Transition(nn.Module):\n",
        "    def __init__(self, inplanes, outplanes):\n",
        "        super(Transition, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = F.avg_pool2d(out, 2)\n",
        "        return out\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_classes, depth=100, block=BasicBlock, dropRate=0, growthRate=12, compressionRate=2, in_channels=1):\n",
        "        super(DenseNet, self).__init__()\n",
        "        assert (depth - 4) % 3 == 0, 'depth should be 3n+4'\n",
        "        n = (depth - 4) // 3 if block == BasicBlock else (depth - 4) // 6\n",
        "        self.growthRate = growthRate\n",
        "        self.dropRate = dropRate\n",
        "        self.inplanes = growthRate * 2\n",
        "        self.conv1 = nn.Conv2d(in_channels, self.inplanes, kernel_size=3, padding=1, bias=False)\n",
        "        self.dense1 = self._make_denseblock(block, n)\n",
        "        self.trans1 = self._make_transition(compressionRate)\n",
        "        self.dense2 = self._make_denseblock(block, n)\n",
        "        self.trans2 = self._make_transition(compressionRate)\n",
        "        self.dense3 = self._make_denseblock(block, n)\n",
        "        self.bn = nn.BatchNorm2d(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AvgPool2d(4)\n",
        "        self.fc = nn.Linear(self.inplanes, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_denseblock(self, block, blocks):\n",
        "        layers = []\n",
        "        for i in range(blocks):\n",
        "            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n",
        "            self.inplanes += self.growthRate\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_transition(self, compressionRate):\n",
        "        inplanes = self.inplanes\n",
        "        outplanes = int(math.floor(self.inplanes // compressionRate))\n",
        "        self.inplanes = outplanes\n",
        "        return Transition(inplanes, outplanes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.trans1(self.dense1(x))\n",
        "        x = self.trans2(self.dense2(x))\n",
        "        x = self.dense3(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DenseNet(num_classes=35, in_channels=1)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model Summary:\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "EL5gN5Ne-W-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_loader\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "D8fyA9_--rFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')"
      ],
      "metadata": {
        "id": "oHoCtSU4_e82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # Sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
      ],
      "metadata": {
        "id": "ZhA7yaEY-e-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    evaluate(model, device, val_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "# Evaluate on test set\n",
        "evaluate(model, device, test_loader)"
      ],
      "metadata": {
        "id": "otBxe9DL_fIv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}